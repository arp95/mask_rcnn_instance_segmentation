{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Dataset\n",
    "\n",
    "In this dataset we will be detecting 3 types of objects: Vehicles, People and animals. The structure of the dataset is as below.\n",
    "\n",
    "1. A numpy array of all the RGB Images (3x300x400)\n",
    "\n",
    "2. A numpy array of all the masks (300x400)\n",
    "\n",
    "3. List of ground truth labels per image\n",
    "\n",
    "4. List of ground truth bounding box per image. The four numbers are the upper left and lower right coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import argparse\n",
    "from PIL import Image\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy \n",
    "%matplotlib inline\n",
    "\n",
    "# Created the Class for the custom dataset\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, root_img, root_mask, root_npy_labels, root_npy_bboxes, transforms = None):\n",
    "        \n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        root_img: The path to the root directory where the image .h5 files are stored\n",
    "        root_mask: The path to the root directory where the mask .h5 files are stored\n",
    "        root_npy_labels: The path to the .npy dataset for labels\n",
    "        root_npy_bboxes: The path to the .npy dataset for the ground truth bounding boxes\n",
    "        transforms: Apply a Pytorch transform to each instance of the image\n",
    "        \n",
    "        \"\"\"\n",
    "        self.root_img = root_img\n",
    "        self.root_mask = root_mask\n",
    "        self.root_npy_labels = root_npy_labels\n",
    "        self.root_npy_bboxes = root_npy_bboxes\n",
    "        self.transforms = transforms \n",
    "        \n",
    "        self.imgs = h5py.File(self.root_img, 'r')\n",
    "        self.mask = h5py.File(self.root_mask, 'r')\n",
    "        self.labels = np.load(self.root_npy_labels, allow_pickle = True)\n",
    "        self.bboxes = np.load(self.root_npy_bboxes, allow_pickle = True)\n",
    "        \n",
    "    # To support indexing when an object of the CustomDataset Class is created\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # Convert the Masks and the input image into an array\n",
    "        image = np.array(self.imgs['data']).astype('int32')\n",
    "        masks = np.array(self.mask['data']).astype('int32')\n",
    "        \n",
    "        # Convert the Mask, image, bounding boxes and labels to a Pytorch Tensor\n",
    "        image = torch.as_tensor(image[index])\n",
    "        masks = torch.as_tensor(masks[index])\n",
    "        bounding_boxes = torch.as_tensor(self.bboxes[index])\n",
    "        labels = torch.as_tensor(self.labels[index])\n",
    "        \n",
    "        batch = {} \n",
    "        batch[\"bounding_boxes\"] = bounding_boxes\n",
    "        batch[\"masks\"] = masks\n",
    "        batch[\"labels\"] = labels\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            image, batch = self.transforms(image,batch)\n",
    "        return image, batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.int32),\n",
       " {'bounding_boxes': tensor([[100.0000, 120.0094, 207.8875, 268.9359],\n",
       "          [183.9109,  85.9969, 263.7531, 274.3828]]),\n",
       "  'masks': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.int32),\n",
       "  'labels': tensor([1, 2])})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root1 = 'C:\\\\Users\\\\shant\\\\Mask_RCNN_Segmentation\\\\dataset\\\\mycocodata_img_comp_zlib.h5'\n",
    "root2 = 'C:\\\\Users\\\\shant\\\\Mask_RCNN_Segmentation\\\\dataset\\\\mycocodata_mask_comp_zlib.h5'\n",
    "root3_npy = 'C:\\\\Users\\\\shant\\\\Mask_RCNN_Segmentation\\\\dataset\\\\mycocodata_labels_comp_zlib.npy'\n",
    "root4_npy = 'C://Users//shant//Mask_RCNN_Segmentation//dataset/mycocodata_bboxes_comp_zlib.npy'\n",
    "\n",
    "dataset = CustomDataset(root1, root2, root3_npy, root4_npy)\n",
    "dataset[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-0f0ba158922a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#torch.as_tensor(labels[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "root1 = 'C:\\\\Users\\\\shant\\\\Mask_RCNN_Segmentation\\\\dataset\\\\mycocodata_img_comp_zlib.h5'\n",
    "root2 = 'C:\\\\Users\\\\shant\\\\Mask_RCNN_Segmentation\\\\dataset\\\\mycocodata_mask_comp_zlib.h5'\n",
    "img = h5py.File(root1,'r')\n",
    "# You can Inspect what is inside the dataset by using the command list(x.keys())\n",
    "imgs = np.array(img['data']).astype('int32')\n",
    "mask = h5py.File(root2,'r')\n",
    "torch.as_tensor(imgs[0])\n",
    "#masks = np.array(mask['data'])\n",
    "#print(f'Number of images: {imgs.shape} Number of Mask: {masks.shape}')\n",
    "labels = np.load('C:\\\\Users\\\\shant\\\\Mask_RCNN_Segmentation\\\\dataset\\\\mycocodata_labels_comp_zlib.npy', allow_pickle=True)\n",
    "bounding_box = np.load('C:\\\\Users\\\\shant\\\\Mask_RCNN_Segmentation\\\\dataset\\\\mycocodata_bboxes_comp_zlib.npy', allow_pickle = True)\n",
    "#torch.as_tensor(labels[0])\n",
    "imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
